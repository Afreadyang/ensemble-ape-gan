{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TEST_MNIST.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM2ZABv4gikUg29Ml3ueaS/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WgvYLrbtq5Gv"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","import os\r\n","os.chdir('./gdrive/MyDrive/AEGAN/AE_GAN_JOC/APE-GAN')\r\n","!nvidia-smi\r\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pf8QzC6FtoMP"},"source":["!pip install adversarial-robustness-toolbox"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsKQfcxvvj7l"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.optim as optim\r\n","import torchvision\r\n","from torchvision import transforms\r\n","import numpy as np\r\n","from art.attacks.evasion import FastGradientMethod\r\n","from art.attacks.evasion import CarliniL2Method\r\n","from art.attacks.evasion import DeepFool\r\n","from art.attacks.evasion import BasicIterativeMethod\r\n","from art.attacks.evasion import SaliencyMapMethod\r\n","from art.estimators.classification import PyTorchClassifier\r\n","from art.defences.preprocessor import FeatureSqueezing\r\n","from art.defences.preprocessor import TotalVarMin\r\n","from art.defences.preprocessor import SpatialSmoothing\r\n","from art.defences.preprocessor import JpegCompression"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SoNypPx3hb7R"},"source":["def double_conv(in_channels, out_channels):\r\n","    return nn.Sequential(\r\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\r\n","        nn.ReLU(inplace=True),\r\n","        nn.Conv2d(out_channels, out_channels, 3, padding=1),\r\n","        nn.ReLU(inplace=True)\r\n","    )   \r\n","\r\n","# mnist\r\n","class Generator2(nn.Module):\r\n","\r\n","    def __init__(self, in_ch):\r\n","        super(Generator2, self).__init__()      \r\n","        self.dconv_down1 = double_conv(in_ch, 64)\r\n","        self.dconv_down2 = double_conv(64, 128)\r\n","        self.dconv_down3 = double_conv(128, 256)\r\n","        # self.dconv_down4 = double_conv(256, 512)        \r\n","\r\n","        self.maxpool = nn.MaxPool2d(2)\r\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \r\n","        \r\n","        self.dconv_up3 = double_conv(128 + 256, 128)\r\n","        self.dconv_up2 = double_conv(64 + 128, 64)\r\n","        # self.dconv_up1 = double_conv(128 + 64, 64)\r\n","        \r\n","        self.conv_last = nn.Conv2d(64, in_ch, 1)\r\n","        \r\n","        \r\n","    def forward(self, x):\r\n","        conv1 = self.dconv_down1(x)\r\n","        x = self.maxpool(conv1)\r\n","\r\n","        conv2 = self.dconv_down2(x)\r\n","        x = self.maxpool(conv2)\r\n","        \r\n","        x = self.dconv_down3(x)\r\n","        # conv3 = self.dconv_down3(x)\r\n","        # x = self.maxpool(conv3)   \r\n","        \r\n","        # x = self.dconv_down4(x)\r\n","        \r\n","        x = self.upsample(x)        \r\n","        # x = torch.cat([x, conv3], dim=1)\r\n","        x = torch.cat([x, conv2], dim=1)\r\n","        \r\n","        x = self.dconv_up3(x)\r\n","        x = self.upsample(x)        \r\n","        x = torch.cat([x, conv1], dim=1)       \r\n","\r\n","        # x = self.dconv_up2(x)\r\n","        # x = self.upsample(x)        \r\n","        # x = torch.cat([x, conv1], dim=1)   \r\n","        \r\n","        x = self.dconv_up2(x)\r\n","        \r\n","        out = self.conv_last(x)\r\n","        \r\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOlP7ieYhqc8"},"source":["G1 = Generator2(1).cuda()\r\n","G1.load_state_dict(torch.load(\"./checkpoint/mnist_test/5.tar\")[\"generator\"])\r\n","G1.eval()\r\n","\r\n","G2 = Generator2(1).cuda()\r\n","G2.load_state_dict(torch.load(\"./checkpoint/mnist_test/6.tar\")[\"generator\"])\r\n","G2.eval()\r\n","\r\n","G3 = Generator2(1).cuda()\r\n","G3.load_state_dict(torch.load(\"./checkpoint/mnist_test/7.tar\")[\"generator\"])\r\n","G3.eval()\r\n","\r\n","G4 = Generator2(1).cuda()\r\n","G4.load_state_dict(torch.load(\"./checkpoint/mnist_test/8.tar\")[\"generator\"])\r\n","G4.eval()\r\n","\r\n","G5 = Generator2(1).cuda()\r\n","G5.load_state_dict(torch.load(\"./checkpoint/mnist_test/9.tar\")[\"generator\"])\r\n","G5.eval()\r\n","\r\n","G6 = Generator2(1).cuda()\r\n","G6.load_state_dict(torch.load(\"./checkpoint/mnist_test/10.tar\")[\"generator\"])\r\n","G6.eval()\r\n","\r\n","G7 = Generator2(1).cuda()\r\n","G7.load_state_dict(torch.load(\"./checkpoint/mnist_test/11.tar\")[\"generator\"])\r\n","G7.eval()\r\n","\r\n","G8 = Generator2(1).cuda()\r\n","G8.load_state_dict(torch.load(\"./checkpoint/mnist_test/12.tar\")[\"generator\"])\r\n","G8.eval()\r\n","\r\n","G9 = Generator2(1).cuda()\r\n","G9.load_state_dict(torch.load(\"./checkpoint/mnist_test/13.tar\")[\"generator\"])\r\n","G9.eval()\r\n","\r\n","G10 = Generator2(1).cuda()\r\n","G10.load_state_dict(torch.load(\"./checkpoint/mnist_test/14.tar\")[\"generator\"])\r\n","G10.eval()\r\n","\r\n","G11 = Generator2(1).cuda()\r\n","G11.load_state_dict(torch.load(\"./checkpoint/mnist_test/15.tar\")[\"generator\"])\r\n","G11.eval()\r\n","\r\n","G12 = Generator2(1).cuda()\r\n","G12.load_state_dict(torch.load(\"./checkpoint/mnist_test/16.tar\")[\"generator\"])\r\n","G12.eval()\r\n","\r\n","G13 = Generator2(1).cuda()\r\n","G13.load_state_dict(torch.load(\"./checkpoint/mnist_test/17.tar\")[\"generator\"])\r\n","G13.eval()\r\n","\r\n","G14 = Generator2(1).cuda()\r\n","G14.load_state_dict(torch.load(\"./checkpoint/mnist_test/18.tar\")[\"generator\"])\r\n","G14.eval()\r\n","\r\n","G15 = Generator2(1).cuda()\r\n","G15.load_state_dict(torch.load(\"./checkpoint/mnist_test/19.tar\")[\"generator\"])\r\n","G15.eval()\r\n","\r\n","G16 = Generator2(1).cuda()\r\n","G16.load_state_dict(torch.load(\"./checkpoint/mnist_test/20.tar\")[\"generator\"])\r\n","G16.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9wIHQYsJ3xd"},"source":["class Generator(nn.Module):\r\n","\r\n","    def __init__(self, in_ch):\r\n","        super(Generator, self).__init__()\r\n","        self.conv1 = nn.Conv2d(in_ch, 64, 4, stride=2, padding=1)\r\n","        self.bn1 = nn.BatchNorm2d(64)\r\n","        self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\r\n","        self.bn2 = nn.BatchNorm2d(128)\r\n","        self.deconv3 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1)\r\n","        self.bn3 = nn.BatchNorm2d(64)\r\n","        self.deconv4 = nn.ConvTranspose2d(64, in_ch, 4, stride=2, padding=1)\r\n","\r\n","    def forward(self, x):\r\n","        h = F.leaky_relu(self.bn1(self.conv1(x)))\r\n","        h = F.leaky_relu(self.bn2(self.conv2(h)))\r\n","        h = F.leaky_relu(self.bn3(self.deconv3(h)))\r\n","        h = torch.tanh(self.deconv4(h))\r\n","        return h"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dexoEtLuKKEC"},"source":["G = Generator(1).cuda()\r\n","G.load_state_dict(torch.load(\"./mnist_3.tar\")[\"generator\"])\r\n","G.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5HdnTuBf06s4"},"source":["test_loader = torch.utils.data.DataLoader(\r\n","            torchvision.datasets.MNIST(root = './', train=False, download=False,\r\n","                           transform=torchvision.transforms.Compose([\r\n","                               torchvision.transforms.ToTensor()])),\r\n","            batch_size=128, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhwI3Z4G1wOO"},"source":["class BasicBlock(nn.Module):\r\n","    expansion = 1\r\n","\r\n","    def __init__(self, in_planes, planes, stride=1):\r\n","        super(BasicBlock, self).__init__()\r\n","        self.conv1 = nn.Conv2d(\r\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\r\n","                               stride=1, padding=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","\r\n","        self.shortcut = nn.Sequential()\r\n","        if stride != 1 or in_planes != self.expansion*planes:\r\n","            self.shortcut = nn.Sequential(\r\n","                nn.Conv2d(in_planes, self.expansion*planes,\r\n","                          kernel_size=1, stride=stride, bias=False),\r\n","                nn.BatchNorm2d(self.expansion*planes)\r\n","            )\r\n","\r\n","    def forward(self, x):\r\n","        out = F.relu(self.bn1(self.conv1(x)))\r\n","        out = self.bn2(self.conv2(out))\r\n","        out += self.shortcut(x)\r\n","        out = F.relu(out)\r\n","        return out\r\n","\r\n","\r\n","class Bottleneck(nn.Module):\r\n","    expansion = 4\r\n","\r\n","    def __init__(self, in_planes, planes, stride=1):\r\n","        super(Bottleneck, self).__init__()\r\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\r\n","                               stride=stride, padding=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.conv3 = nn.Conv2d(planes, self.expansion *\r\n","                               planes, kernel_size=1, bias=False)\r\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\r\n","\r\n","        self.shortcut = nn.Sequential()\r\n","        if stride != 1 or in_planes != self.expansion*planes:\r\n","            self.shortcut = nn.Sequential(\r\n","                nn.Conv2d(in_planes, self.expansion*planes,\r\n","                          kernel_size=1, stride=stride, bias=False),\r\n","                nn.BatchNorm2d(self.expansion*planes)\r\n","            )\r\n","\r\n","    def forward(self, x):\r\n","        out = F.relu(self.bn1(self.conv1(x)))\r\n","        out = F.relu(self.bn2(self.conv2(out)))\r\n","        out = self.bn3(self.conv3(out))\r\n","        out += self.shortcut(x)\r\n","        out = F.relu(out)\r\n","        return out\r\n","\r\n","\r\n","class ResNet(nn.Module):\r\n","    def __init__(self, block, num_blocks, num_classes=10):\r\n","        super(ResNet, self).__init__()\r\n","        self.in_planes = 64\r\n","\r\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\r\n","                               stride=1, padding=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(64)\r\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\r\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\r\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\r\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\r\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\r\n","\r\n","    def _make_layer(self, block, planes, num_blocks, stride):\r\n","        strides = [stride] + [1]*(num_blocks-1)\r\n","        layers = []\r\n","        for stride in strides:\r\n","            layers.append(block(self.in_planes, planes, stride))\r\n","            self.in_planes = planes * block.expansion\r\n","        return nn.Sequential(*layers)\r\n","\r\n","    def forward(self, x):\r\n","        out = F.relu(self.bn1(self.conv1(x)))\r\n","        out = self.layer1(out)\r\n","        out = self.layer2(out)\r\n","        out = self.layer3(out)\r\n","        out = self.layer4(out)\r\n","        out = F.avg_pool2d(out, 4)\r\n","        out = out.view(out.size(0), -1)\r\n","        out = self.linear(out)\r\n","        return out\r\n","\r\n","\r\n","def ResNet18():\r\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\r\n","\r\n","\r\n","def ResNet34():\r\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\r\n","\r\n","\r\n","def ResNet50():\r\n","    return ResNet(Bottleneck, [3, 4, 6, 3])\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueXiQRmT13da"},"source":["model = ResNet18().cuda()\r\n","model.load_state_dict(torch.load(\"./resnet/mnist_resNet18.tar\")[\"state_dict\"])\r\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCeQYca_23vU"},"source":["criterion = nn.CrossEntropyLoss()\r\n","optimizer = optim.Adam(model.parameters(), lr=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_bFpMoB3J4v"},"source":["classifier = PyTorchClassifier(\r\n","    model=model,\r\n","    clip_values=(0, 1),\r\n","    loss=criterion,\r\n","    optimizer=optimizer,\r\n","    input_shape=(1, 28, 28),\r\n","    nb_classes=10,\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aiO1dkQn21VH"},"source":["accuracy = 0\r\n","for x_test, y_test in test_loader:\r\n","  predictions = classifier.predict(x_test)\r\n","  accuracy += np.sum(np.argmax(predictions, axis=1) == y_test.numpy())\r\n","print('Accuracy on benign test examples:{}%'.format(accuracy/10000*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPDEGIcD4E9q"},"source":["# attack_fgsm = FastGradientMethod(estimator=classifier,eps=0.1)\r\n","# attack_fgsm = BasicIterativeMethod(estimator=classifier, eps=0.1)\r\n","# attack_fgsm = SaliencyMapMethod(classifier=classifier, theta=0.3, gamma=0.8)\r\n","# attack_fgsm = DeepFool(classifier=classifier)\r\n","attack_fgsm = CarliniL2Method(classifier=classifier, confidence=0.0001,binary_search_steps=25, max_iter=25)\r\n","adv_fgsm_accuracy = 0\r\n","re_accuracy = 0\r\n","num = 0\r\n","for x_test, y_test in test_loader:\r\n","  adv_fgsm = attack_fgsm.generate(x=x_test)\r\n","  # torch.save({\"CW\":adv_fgsm,\"y\":y_test}, \"CW.tar\")\r\n","  adv_fgsm_predictions = classifier.predict(adv_fgsm)\r\n","  adv_fgsm_accuracy += np.sum(np.argmax(adv_fgsm_predictions, axis=1) == y_test.numpy())\r\n","\r\n","  re_x1 = G1(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y1 = classifier.predict(re_x1.cpu().detach().numpy())\r\n","\r\n","  re_x2 = G2(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y2 = classifier.predict(re_x2.cpu().detach().numpy())\r\n","\r\n","  re_x3 = G3(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y3 = classifier.predict(re_x3.cpu().detach().numpy())\r\n","\r\n","  re_x4 = G4(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y4 = classifier.predict(re_x4.cpu().detach().numpy())\r\n","\r\n","  re_x5 = G5(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y5 = classifier.predict(re_x5.cpu().detach().numpy())\r\n","\r\n","  re_x6 = G6(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y6 = classifier.predict(re_x6.cpu().detach().numpy())\r\n","\r\n","  re_x7 = G7(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y7 = classifier.predict(re_x7.cpu().detach().numpy())\r\n","\r\n","  re_x8 = G8(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y8 = classifier.predict(re_x8.cpu().detach().numpy())\r\n","\r\n","  re_x9 = G9(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y9 = classifier.predict(re_x9.cpu().detach().numpy())\r\n","\r\n","  re_x10 = G10(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y10 = classifier.predict(re_x10.cpu().detach().numpy())\r\n","\r\n","  re_x11 = G11(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y11 = classifier.predict(re_x11.cpu().detach().numpy())\r\n","\r\n","  re_x12 = G12(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y12 = classifier.predict(re_x12.cpu().detach().numpy())\r\n","\r\n","  re_x13 = G13(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y13 = classifier.predict(re_x13.cpu().detach().numpy())\r\n","\r\n","  re_x14 = G14(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y14 = classifier.predict(re_x14.cpu().detach().numpy())\r\n","\r\n","  re_x15 = G15(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y15 = classifier.predict(re_x15.cpu().detach().numpy())\r\n","\r\n","  re_x16 = G16(torch.from_numpy(adv_fgsm).cuda())\r\n","  re_y16 = classifier.predict(re_x16.cpu().detach().numpy())\r\n","\r\n","  # re_y = (re_y1 + re_y2 + re_y3 + re_y4 + re_y5 + re_y6 + re_y7 + re_y8 + re_y9 + re_y10 + re_y11 + re_y12 + re_y13)/13\r\n","  re_y = re_y1\r\n","  # 0.01\r\n","  # re_y = (re_y7 + re_y9 + re_y11 + re_y12 + re_y13)/5\r\n","  # 0.03\r\n","  # re_y = (re_y9 + re_y10 + re_y12 + re_y13)/4\r\n","  # 0.05\r\n","  # re_y = (re_y5 + re_y7 + re_y8 + re_y10)/4\r\n","  # 0.07\r\n","  # re_y = (re_y2 + re_y3 + re_y4 + re_y5 + re_y6 + re_y8 + re_y10)/7\r\n","  # 0.1\r\n","  # re_y = (re_y1 + re_y2 + re_y4 + re_y5 + re_y6 + re_y8 + re_y10)/7\r\n","  # 0.3\r\n","  # re_y = (re_y1 + re_y4 + re_y5 + re_y6 + re_y9 + re_y10)/6\r\n","  # 0.5\r\n","  # re_y = (re_y6 + re_y7 + re_y8 + re_y10)/4\r\n","  # 0.7\r\n","  # re_y = (re_y6 + re_y10 + re_y12 + re_y13)/4\r\n","  # APE-GAN\r\n","  # re_x = G(torch.from_numpy(adv_fgsm).cuda())\r\n","  # re_y = classifier.predict(re_x.cpu().detach().numpy())\r\n","  # bit_depth\r\n","  # defense0 = FeatureSqueezing(clip_values=(0.0,0.8),bit_depth=1)\r\n","  # re_x = defense0(adv_fgsm)[0]\r\n","  # re_y = classifier.predict(re_x)\r\n","  # TotalVarMin\r\n","  # defense2 = TotalVarMin()\r\n","  # re_x = defense2(adv_fgsm)[0]\r\n","  # re_y = classifier.predict(re_x)\r\n","  # SpatialSmoothing\r\n","  # defense3 = SpatialSmoothing(window_size=2)\r\n","  # re_x = defense3(adv_fgsm)[0]\r\n","  # re_y = classifier.predict(re_x)\r\n","  # JpegCompression\r\n","  # defense4 = JpegCompression(clip_values=(0.0,1.0))\r\n","  # re_x = defense4(adv_fgsm)[0]\r\n","  # re_y = classifier.predict(re_x)\r\n","  # FGSM\r\n","  # 0.1\r\n","  # re_y = (re_y1 + re_y2 + re_y3 + re_y4 + re_y5 + re_y6 + re_y7 + re_y8 + re_y9 + re_y10 + re_y11 + re_y12 + re_y13 + re_y14 + re_y15 + re_y16)/16\r\n","  # 0.3\r\n","  # re_y = (re_y8 + re_y9 + re_y10 + re_y11 + re_y12 + re_y13 + re_y14 + re_y15 + re_y16)/9\r\n","  # 0.5\r\n","  # re_y = (re_y3 + re_y8 + re_y11 + re_y13 + re_y16)/5\r\n","  # 0.7\r\n","  # re_y = (re_y1 + re_y2 + re_y3 + re_y4 + re_y5 + re_y6 + re_y7 + re_y8 + re_y9 + re_y10 + re_y11 + re_y12 + re_y13 + re_y14 + re_y15 + re_y16)/16\r\n","  # BIM\r\n","  # 0.1\r\n","  # re_y = (re_y6 + re_y9 + re_y10 + re_y11 + re_y13 + re_y14 + re_y15 + re_y16)/8\r\n","  # 0.3\r\n","  # re_y = (re_y13 + re_y14 + re_y15 + re_y16)/4\r\n","  # re_y = (re_y1 + re_y3 + re_y8)/3\r\n","  # JSMA\r\n","  # re_y = (re_y1 + re_y2 + re_y3 + re_y4 + re_y5 + re_y6 + re_y7 + re_y8 + re_y9 + re_y10 + re_y11 + re_y12 + re_y13 + re_y14 + re_y15 + re_y16)/16\r\n","  # deepfool\r\n","  # re_y = (re_y1 + re_y3)/2\r\n","\r\n","  re_accuracy += np.sum(np.argmax(re_y, axis=1) == y_test.numpy())\r\n","  num = num + len(x_test)\r\n","  print(adv_fgsm_accuracy/num*100)\r\n","  print(re_accuracy/num*100)\r\n","  if num>100:\r\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsUpVc1PVuBR"},"source":["cw = torch.load('./CW.tar')\r\n","adv_fgsm = cw['CW']\r\n","y_test = cw['y']\r\n","adv_fgsm_predictions = classifier.predict(adv_fgsm)\r\n","adv_fgsm_accuracy = np.sum(np.argmax(adv_fgsm_predictions, axis=1) == y_test.numpy())\r\n","\r\n","re_x1 = G1(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y1 = classifier.predict(re_x1.cpu().detach().numpy())\r\n","\r\n","re_x2 = G2(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y2 = classifier.predict(re_x2.cpu().detach().numpy())\r\n","\r\n","re_x3 = G3(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y3 = classifier.predict(re_x3.cpu().detach().numpy())\r\n","\r\n","re_x4 = G4(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y4 = classifier.predict(re_x4.cpu().detach().numpy())\r\n","\r\n","re_x5 = G5(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y5 = classifier.predict(re_x5.cpu().detach().numpy())\r\n","\r\n","re_x6 = G6(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y6 = classifier.predict(re_x6.cpu().detach().numpy())\r\n","\r\n","re_x7 = G7(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y7 = classifier.predict(re_x7.cpu().detach().numpy())\r\n","\r\n","re_x8 = G8(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y8 = classifier.predict(re_x8.cpu().detach().numpy())\r\n","\r\n","re_x9 = G9(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y9 = classifier.predict(re_x9.cpu().detach().numpy())\r\n","\r\n","re_x10 = G10(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y10 = classifier.predict(re_x10.cpu().detach().numpy())\r\n","\r\n","re_x11 = G11(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y11 = classifier.predict(re_x11.cpu().detach().numpy())\r\n","\r\n","re_x12 = G12(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y12 = classifier.predict(re_x12.cpu().detach().numpy())\r\n","\r\n","re_x13 = G13(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y13 = classifier.predict(re_x13.cpu().detach().numpy())\r\n","\r\n","re_x14 = G14(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y14 = classifier.predict(re_x14.cpu().detach().numpy())\r\n","\r\n","re_x15 = G15(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y15 = classifier.predict(re_x15.cpu().detach().numpy())\r\n","\r\n","re_x16 = G16(torch.from_numpy(adv_fgsm).cuda())\r\n","re_y16 = classifier.predict(re_x16.cpu().detach().numpy())\r\n","\r\n","# re_y = re_y1\r\n","\r\n","# APE-GAN\r\n","# re_x = G(torch.from_numpy(adv_fgsm).cuda())\r\n","# re_y = classifier.predict(re_x.cpu().detach().numpy())\r\n","# bit_depth\r\n","# defense0 = FeatureSqueezing(clip_values=(0.0,0.8),bit_depth=1)\r\n","# re_x = defense0(adv_fgsm)[0]\r\n","# re_y = classifier.predict(re_x)\r\n","# TotalVarMin\r\n","# defense2 = TotalVarMin()\r\n","# re_x = defense2(adv_fgsm)[0]\r\n","# re_y = classifier.predict(re_x)\r\n","# SpatialSmoothing\r\n","defense3 = SpatialSmoothing(window_size=2)\r\n","re_x = defense3(adv_fgsm)[0]\r\n","re_y = classifier.predict(re_x)\r\n","\r\n","re_accuracy = np.sum(np.argmax(re_y, axis=1) == y_test.numpy())\r\n","print(adv_fgsm_accuracy/len(y_test)*100)\r\n","print(re_accuracy/len(y_test)*100)"],"execution_count":null,"outputs":[]}]}